{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "458dd7c3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding */DPFlow/architecture_files to sys.path\n",
      "sys.path = \n",
      "\t/opt/conda/lib/python311.zip\n",
      "\t/opt/conda/lib/python3.11\n",
      "\t/opt/conda/lib/python3.11/lib-dynload\n",
      "\t\n",
      "\t/opt/conda/lib/python3.11/site-packages\n",
      "\t/home/jsorge/private/final_project/DPFlow\n",
      "Using cuda device.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "path_list = sys.path\n",
    "found_directories = False\n",
    "for path_variable in path_list:\n",
    "    if \"DPFlow\" in path_variable:\n",
    "        found_directories = True\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "if not found_directories:\n",
    "    print(f\"Adding */DPFlow/architecture_files to sys.path\")\n",
    "    sys.path.append(\"/home/jsorge/private/final_project/DPFlow\")\n",
    "    # sys.path.append(\"/home/yix050/private/ECE285_Visual_25Spring/final_project/DPFlow\")\n",
    "    print(f\"sys.path = \")\n",
    "    for idx in range(len(sys.path)):\n",
    "        print(f\"\\t{sys.path[idx]}\") \n",
    "from architecture_files.cross_gated_unit import CrossGateBlock, DownsamplingLayer\n",
    "from architecture_files.res_stem import ResStem\n",
    "from architecture_files.conv_gru_cell import ConvGRUCell\n",
    "\n",
    "# Set device to CUDA\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2149417",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class BidirEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    The hidden_channels is always [64, 96, 128] in the DPFlow paper, and pyramid_level = 3\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 hidden_channels=[64, 96, 128]):\n",
    "        super().__init__()\n",
    "\n",
    "        ### Conv Stem: takes the raw image as input and outputs X0 and H0 ###\n",
    "        self.conv_stem = ResStem([hidden_channels[0], hidden_channels[1], 2 * hidden_channels[2]])\n",
    "        self.lower_stem = ResStem([hidden_channels[0], hidden_channels[1], hidden_channels[2]])\n",
    "\n",
    "        ### Forward GRU ###\n",
    "        self.forward_gru = ConvGRUCell(hidden_channels[-1], hidden_channels[-1])\n",
    "        # for passing Hf to the lower scale level. H_out = H_in/2\n",
    "        self.down_gru = nn.Conv2d(hidden_channels[-1], hidden_channels[-1], kernel_size=3, stride=2, padding=1, bias=True) \n",
    "\n",
    "        ### Backward GRU ###\n",
    "        self.backward_gru = ConvGRUCell(hidden_channels[-1], hidden_channels[-1])\n",
    "        # for passing Hb and Xb to the higher scale level. H_out = 2*H_in\n",
    "        self.up_gru = nn.ConvTranspose2d(hidden_channels[-1], hidden_channels[-1], kernel_size=4, stride=2, padding=1, bias=True) \n",
    "\n",
    "        ### Forward CGU ###\n",
    "        self.downsampling = DownsamplingLayer(channels=hidden_channels[-1])\n",
    "        self.forward_cgu = CrossGateBlock(num_channels_in=hidden_channels[-1], \n",
    "                                          num_channels_hidden=hidden_channels[-1], \n",
    "                                          norm_type=\"batch_norm\", \n",
    "                                          use_dropout=True, \n",
    "                                          use_layer_scale=False)\n",
    "        \n",
    "        ### Backward CGU ###\n",
    "        self.backward_cgu = CrossGateBlock(num_channels_in=hidden_channels[-1], \n",
    "                                          num_channels_hidden=hidden_channels[-1], \n",
    "                                          norm_type=\"batch_norm\", \n",
    "                                          use_dropout=True, \n",
    "                                          use_layer_scale=False)\n",
    "\n",
    "        ### Output layer ###\n",
    "        self.num_out_stages = 1 # DPFlow always sets this to 1\n",
    "        self.out_1x1_abs_chs = 384 # DPFlow always sets this to 384\n",
    "        self.out_1x1_factor = None\n",
    "\n",
    "        if self.num_out_stages > 0:\n",
    "            # This out_merge_conv has a ReLU layer before it\n",
    "            self.out_merge_conv = nn.Conv2d(3 * hidden_channels[-1], hidden_channels[-1], kernel_size=1)\n",
    "            self.out_cgu = CrossGateBlock(num_channels_in=hidden_channels[-1], \n",
    "                                          num_channels_hidden=hidden_channels[-1], \n",
    "                                          norm_type=\"batch_norm\", \n",
    "                                          use_dropout=True, \n",
    "                                          use_layer_scale=False)\n",
    "        if self.out_1x1_abs_chs > 0:\n",
    "            self.out_1x1 = nn.Conv2d(hidden_channels[-1], self.out_1x1_abs_chs, kernel_size=1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.tensor, y: torch.tensor, pyr_levels: int):\n",
    "        \"\"\"\n",
    "        Takes two frames of image x and y as input. x and y will go through the same process separately.\n",
    "        @param x: a raw image\n",
    "        @param y: a raw image\n",
    "\n",
    "        @return: Two feature pyramids x_pyramid[::-1], y_pyramid[::-1] as the embeddings to pass to the decode\n",
    "        \"\"\"\n",
    "\n",
    "        # input_x = x # for concatenation in the final feature pyramid\n",
    "        # input_y = y # for concatenation in the final feature pyramid\n",
    "        \n",
    "        x0, hx0 = self._get_init_stat(x)\n",
    "        y0, hy0 = self._get_init_stat(y)\n",
    "        \n",
    "        x_pyramid, y_pyramid = self._encode(x0, hx0, y0, hy0, pyr_levels, x, y)\n",
    "        \n",
    "        return x_pyramid[::-1], y_pyramid[::-1]\n",
    "\n",
    "    \n",
    "    def _encode(self, x0, hx0, y0, hy0, pyr_levels, input_x, input_y):\n",
    "        #TODO: Implement the dual-pyramid encoder block\n",
    "        \"\"\"\n",
    "        Go through the forward process (high scale to low scale) and then the backward process (low scale to high scale)\n",
    "        Returns the feature pyramids x_pyramid and y_pyramid\n",
    "        \"\"\"\n",
    "        \n",
    "        x_pyramid = [None] * 3 # store concatenation of xf, xb, xi for each scale\n",
    "        y_pyramid = [None] * 3 # store concatenation of yf, yb, yi for each scale\n",
    "        \n",
    "        # input_x = x0 # for concatenation in the final feature pyramid\n",
    "        # input_y = y0 # for concatenation in the final feature pyramid\n",
    "        \n",
    "        ####### Forward Start #######\n",
    "        x_forwards = []\n",
    "        y_forwards = []\n",
    "\n",
    "        x_f, hx_f = x0, hx0\n",
    "        y_f, hy_f = y0, hy0\n",
    "        \n",
    "        for i in range(pyr_levels):\n",
    "            hx_f = self.forward_gru(x_f, hx_f)\n",
    "            hy_f = self.forward_gru(y_f, hy_f)\n",
    "\n",
    "            x_f, y_f = self.forward_cgu(hx_f, hy_f) # this is used as xf for the next scale, and in the final concatenation\n",
    "            x_f = self.downsampling(x_f)\n",
    "            y_f = self.downsampling(y_f)\n",
    "            x_f = x_f.contiguous() # make the data contiguous to speed up the computation?\n",
    "            y_f = y_f.contiguous()\n",
    "\n",
    "            # downsample the forward h\n",
    "            if (i < pyr_levels - 1): # don't do the down_gru for the lowest level\n",
    "                hx_f = torch.tanh(self.down_gru(hx_f))\n",
    "                hy_f = torch.tanh(self.down_gru(hy_f))\n",
    "\n",
    "            x_forwards.append(x_f)\n",
    "            y_forwards.append(y_f)\n",
    "        ####### Forward End #######\n",
    "        \n",
    "\n",
    "        ####### Backward Start #######\n",
    "        # Initialize the hx and hy when doing backward from the lowest scale layer\n",
    "        hx_b = torch.zeros_like(x_forwards[-1])\n",
    "        hy_b = torch.zeros_like(y_forwards[-1])\n",
    "\n",
    "        for i in range(len(x_forwards) - 1, -1, -1):\n",
    "            x_f = x_forwards[i]\n",
    "            y_f = y_forwards[i]\n",
    "\n",
    "            hx_b = self.backward_gru(x_f, hx_b)\n",
    "            hy_b = self.backward_gru(y_f, hy_b)\n",
    "\n",
    "            x_b, y_b = self.backward_cgu(hx_b, hy_b)\n",
    "\n",
    "            # Downsample the input for concatenating with different scales, (1/2, 1/4, 1/8) for each scale.\n",
    "            input_x_lower = F.interpolate(input_x, scale_factor=(1 / 2**(i+1)), mode='bilinear', align_corners=True)\n",
    "            input_y_lower = F.interpolate(input_y, scale_factor=(1 / 2**(i+1)), mode='bilinear', align_corners=True)\n",
    "            \n",
    "            input_x_lower = self.lower_stem(input_x_lower)\n",
    "            input_y_lower = self.lower_stem(input_y_lower)\n",
    "\n",
    "            # These pyramids are the output of this Encoder\n",
    "            # Sizes of tensors must match except in dimension 1 (height and width must match, will concate along the channel).\n",
    "            x_pyramid[i] = torch.cat([x_f, x_b, input_x_lower], 1)\n",
    "            y_pyramid[i] = torch.cat([y_f, y_b, input_y_lower], 1) \n",
    "            \n",
    "            # upsample the backward h\n",
    "            if i > 0:\n",
    "                hx_b = torch.tanh(self.up_gru(hx_b))\n",
    "                hy_b = torch.tanh(self.up_gru(hy_b))\n",
    "        ####### Backward End #######\n",
    "\n",
    "        ####### Output Layers ######\n",
    "        for i, (x, y) in enumerate(zip(x_pyramid, y_pyramid)):\n",
    "            if self.num_out_stages > 0:\n",
    "                x = self.out_merge_conv(F.relu(x))\n",
    "                y = self.out_merge_conv(F.relu(y))\n",
    "                x, y = self.out_cgu(x, y)\n",
    "            if self.out_1x1_abs_chs > 0:\n",
    "                if self.out_1x1_factor is None:\n",
    "                    x = self.out_1x1(x)\n",
    "                    y = self.out_1x1(y)\n",
    "                else:\n",
    "                    x = self.out_1x1(x, int(self.out_1x1_factor * x.shape[1]))\n",
    "                    y = self.out_1x1(y, int(self.out_1x1_factor * y.shape[1]))\n",
    "            x_pyramid[i] = x\n",
    "            y_pyramid[i] = y\n",
    "        \n",
    "        \n",
    "        return x_pyramid, y_pyramid\n",
    "\n",
    "\n",
    "    def _get_init_stat(self, x):\n",
    "        \"\"\"\n",
    "        Pass the input image x to the conv_stem, and return x0, h0\n",
    "        \"\"\"\n",
    "        x = self.conv_stem(x)\n",
    "        x, hx = torch.split(x, [x.shape[1] // 2, x.shape[1] // 2], 1)\n",
    "        hx = torch.tanh(hx)\n",
    "        return x, hx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149660fa-baf9-4994-b351-dab1639d000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_img1 = torch.rand((2, 3, 256, 256), device=device)\n",
    "example_img2 = torch.rand((2, 3, 256, 256), device=device)\n",
    "example_pyr_levels = 3\n",
    "\n",
    "model = BidirEncoder()\n",
    "model.to(device)\n",
    "output = model(example_img1, example_img2, example_pyr_levels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
