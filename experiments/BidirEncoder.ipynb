{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "458dd7c3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2149417",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class BidirEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    The hidden_channels is always [64, 96, 128] in the DPFlow paper, and pyramid_level = 3\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        ### Conv Stem: takes the raw image as input and outputs X0 and H0 ###\n",
    "        self.conv_stem = ResStem([hidden_channels[0], hidden_channels[1], 2 * hidden_channels[2]])\n",
    "        self.lower_stem = ResStem([hidden_channels[0], hidden_channels[1], hidden_channels[2]])\n",
    "\n",
    "        ### Forward GRU ###\n",
    "        self.forward_gru = ConvGRUCell(hidden_channels[-1], hidden_channels[-1])\n",
    "        # for passing Hf to the lower scale level. H_out = H_in/2\n",
    "        self.down_gru = nn.Conv2d(hidden_channels[-1], hidden_channels[-1], kernel_size=3, stride=2, padding=1, bias=True) \n",
    "\n",
    "        ### Backward GRU ###\n",
    "        self.backward_gru = ConvGRUCell(hidden_channels[-1], hidden_channels[-1])\n",
    "        # for passing Hb and Xb to the higher scale level. H_out = 2*H_in\n",
    "        self.up_gru = nn.ConvTranspose2d(hidden_channels[-1], hidden_channels[-1], kernel_size=4, stride=2, padding=1, bias=True) \n",
    "\n",
    "        ### Forward CGU ###\n",
    "        #TODO: forward cgu blocks\n",
    "        #self.forward_cgu = \n",
    "        \n",
    "        ### Backward CGU ###\n",
    "        #TODO: backward cgu block\n",
    "        #self.backward_cgu = \n",
    "\n",
    "        ### Output layer ###\n",
    "        self.num_out_stages = 1 # DPFlow always sets this to 1\n",
    "        self.out_1x1_abs_chs = 384 # DPFlow always sets this to 384\n",
    "\n",
    "        if self.num_out_stages > 0:\n",
    "            # This out_merge_conv has a ReLU layer before it\n",
    "            self.out_merge_conv = nn.Conv2d(3 * hidden_channels[-1], hidden_channels[-1], kernel_size=1)\n",
    "            #self.out_cgu = \n",
    "        if self.out_1x1_abs_chs > 0:\n",
    "            self.out_1x1 = nn.Conv2d(hidden_channels[-1], out_1x1_abs_chs, kernel_size=1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.tensor, y: torch.tensor, pyr_levels: int):\n",
    "        \"\"\"\n",
    "        Takes two frames of image x and y as input. x and y will go through the same process separately.\n",
    "        @param x: a raw image\n",
    "        @param y: a raw image\n",
    "\n",
    "        @return: Two feature pyramids x_pyramid[::-1], y_pyramid[::-1] as the embeddings to pass to the decode\n",
    "        \"\"\"\n",
    "\n",
    "        x0, hx0 = self._get_init_stat(x)\n",
    "        y0, hy0 = self._get_init_stat(y)\n",
    "        \n",
    "        x_pyramid, y_pyramid = self._encode(x0, hx0, y0, hy0, pyr_levels)\n",
    "        \n",
    "        return x_pyramid[::-1], y_pyramid[::-1]\n",
    "\n",
    "    \n",
    "    def _encode(self, x0, hx0, y0. hy0, pyr_levels):\n",
    "        #TODO: Implement the dual-pyramid encoder block\n",
    "        \"\"\"\n",
    "        Go through the forward process (high scale to low scale) and then the backward process (low scale to high scale)\n",
    "        Returns the feature pyramids x_pyramid and y_pyramid\n",
    "        \"\"\"\n",
    "        \n",
    "        x_pyramid = [] # store concatenation of xf, xb, xi for each scale\n",
    "        y_pyramid = [] # store concatenation of yf, yb, yi for each scale\n",
    "        \n",
    "        input_x = x # for concatenation in the final feature pyramid\n",
    "        input_y = y # for concatenation in the final feature pyramid\n",
    "        \n",
    "        ####### Forward Start #######\n",
    "        x_forwards = []\n",
    "        y_forwards = []\n",
    "\n",
    "        x_f, hx_f = x0, hx0\n",
    "        y_f, hy_f = y0, hy0\n",
    "        \n",
    "        for i in range(pyr_levels):\n",
    "            hx_f = self.forward_gru(x_f, hx_f)\n",
    "            hy_f = self.forward_gru(y_f, hy_f)\n",
    "\n",
    "            xf, yf = self.forward_cgu(hx, hy) # this is used as xf for the next scale, and in the final concatenation\n",
    "            x_f = x_f.contiguous() # make the data contiguous to speed up the computation?\n",
    "            y_f = y_f.contiguous()\n",
    "\n",
    "            # downsample the forward h\n",
    "            if (i < pyr_levels - 1): # don't do the down_gru for the lowest level\n",
    "                hx_f = torch.tanh(self.down_gru(hx_f))\n",
    "                hy_f = torch.tanh(self.down_gru(hy_f))\n",
    "\n",
    "            x_forwards.append(x_f)\n",
    "            y_forwards.append(y_f)\n",
    "        ####### Forward End #######\n",
    "        \n",
    "\n",
    "        ####### Backward Start #######\n",
    "        # Initialize the hx and hy when doing backward from the lowest scale layer\n",
    "        hx_b = torch.zeros_like(x_forwards[-1])\n",
    "        hy_b = torch.zeros_like(y_forwards[-1])\n",
    "\n",
    "        for i in range(len(pyr_levels) - 1, -1, -1):\n",
    "            x_f = x_forwards[i]\n",
    "            y_f = y_forwards[i]\n",
    "\n",
    "            hx_b = self.backward_gru(x_f, hx_b)\n",
    "            hy_b = self.backward_gru(y_f, hy_b)\n",
    "\n",
    "            x_b, y_b = self.backward_cgu(hx_b, hy_b)\n",
    "\n",
    "            # Downsample the input for concatenating with different scales, (1/2, 1/4, 1/8) for each scale.\n",
    "            input_x_lower = F.interpolate(input_x, scale_factor=(1 / 2**(i+1)), mode='bilinear', align_corners=True)\n",
    "            input_y_lower = F.interpolate(input_y, scale_factor=(1 / 2**(i+1)), mode='bilinear', align_corners=True)\n",
    "            input_x_lower = self.lower_stem(input_x_lower)\n",
    "            input_y_lower = self.lower_stem(input_y_lower)\n",
    "\n",
    "            # These pyramids are the output of this Encoder\n",
    "            # Sizes of tensors must match except in dimension 1 (height and width must match, will concate along the channel).\n",
    "            x_pyramid[i] = torch.cat([x_f, x_b, input_x_lower], 1)\n",
    "            y_pyramid[i] = torch.cat([y_f, y_b, input_y_lower], 1) \n",
    "            \n",
    "            # upsample the backward h\n",
    "            if i > 0:\n",
    "                hx_b = torch.tanh(self.up_gru(hx_b))\n",
    "                hy_b = torch.tanh(self.up_gru(hy_b))\n",
    "        ####### Backward End #######\n",
    "\n",
    "        ####### Output Layers ######\n",
    "        for i (x, y) in enumerate(zip(x_pyramid, y_pyramid)):\n",
    "            if self.num_out_stages > 0:\n",
    "                x = self.out_merge_conv(F.relu(x))\n",
    "                y = self.out_merge_conv(F.relu(y))\n",
    "                x, y = self.out_cgu(x, y)\n",
    "            if self.out_1x1_abs_chs > 0:\n",
    "                if self.out_1x1_factor is None:\n",
    "                    x = self.out_1x1(x)\n",
    "                    y = self.out_1x1(y)\n",
    "                else:\n",
    "                    x = self.out_1x1(x, int(self.out_1x1_factor * x.shape[1]))\n",
    "                    y = self.out_1x1(y, int(self.out_1x1_factor * y.shape[1]))\n",
    "            x_pyramid[i] = x\n",
    "            y_pyramid[i] = y\n",
    "        \n",
    "        \n",
    "        return x_pyramid, y_pyramid\n",
    "\n",
    "\n",
    "    def _get_init_stat(self, x):\n",
    "        \"\"\"\n",
    "        Pass the input image x to the conv_stem, and return x0, h0\n",
    "        \"\"\"\n",
    "        x = self.conv_stem(x)\n",
    "        x, hx = torch.split(x, [x.shape[1] // 2, x.shape[1] // 2], 1)\n",
    "        hx = torch.tanh(hx)\n",
    "        return x, hx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149660fa-baf9-4994-b351-dab1639d000e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
