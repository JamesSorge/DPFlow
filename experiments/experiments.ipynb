{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28d1f170",
   "metadata": {},
   "source": [
    "# DPFlow Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "770fc90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding */ptlflow to sys.path\n",
      "sys.path = \n",
      "\t/opt/conda/lib/python311.zip\n",
      "\t/opt/conda/lib/python3.11\n",
      "\t/opt/conda/lib/python3.11/lib-dynload\n",
      "\t\n",
      "\t/home/yix050/py11kernel/lib/python3.11/site-packages\n",
      "\t/tmp/tmpsibiiybb\n",
      "\t/home/yix050/private/ECE285_Visual_25Spring/final_project/DPFlow/ptlflow/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yix050/py11kernel/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/yix050/py11kernel/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!!alt_cuda_corr is not compiled!!]\n",
      "Adding */DPFlow/architecture_files to sys.path\n",
      "sys.path = \n",
      "\t/opt/conda/lib/python311.zip\n",
      "\t/opt/conda/lib/python3.11\n",
      "\t/opt/conda/lib/python3.11/lib-dynload\n",
      "\t\n",
      "\t/home/yix050/py11kernel/lib/python3.11/site-packages\n",
      "\t/tmp/tmpsibiiybb\n",
      "\t/home/yix050/private/ECE285_Visual_25Spring/final_project/DPFlow/ptlflow/\n",
      "\t/home/yix050/private/ECE285_Visual_25Spring/final_project/DPFlow\n",
      "Using cuda device.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import sys\n",
    "\n",
    "path_list = sys.path\n",
    "found_directories = False\n",
    "for path_variable in path_list:\n",
    "    if \"DPFlow\" in path_variable:\n",
    "        found_directories = True\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "if not found_directories:\n",
    "    print(f\"Adding */ptlflow to sys.path\")\n",
    "    #sys.path.append(\"/home/jsorge/private/final_project/DPFlow/ptlflow/\")\n",
    "    sys.path.append(\"/home/yix050/private/ECE285_Visual_25Spring/final_project/DPFlow/ptlflow/\")\n",
    "    print(f\"sys.path = \")\n",
    "    for idx in range(len(sys.path)):\n",
    "        print(f\"\\t{sys.path[idx]}\") \n",
    "\n",
    "import math\n",
    "from typing import Optional\n",
    "\n",
    "from loguru import logger\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ptlflow.models.base_model.base_model import BaseModel\n",
    "from ptlflow.models.dpflow.corr import CorrBlock, AlternateCorrBlock\n",
    "from ptlflow.models.dpflow.pwc_modules import rescale_flow, upsample2d_as\n",
    "from ptlflow.models.dpflow.cgu_bidir_dual_encoder import CGUBidirDualEncoder\n",
    "from ptlflow.models.dpflow.update import UpdateBlock\n",
    "from ptlflow.models.dpflow.utils import (\n",
    "    compute_pyramid_levels,\n",
    "    get_activation,\n",
    "    get_norm,\n",
    ")\n",
    "from ptlflow.utils.utils import forward_interpolate_batch\n",
    "from ptlflow.utils.registry import register_model, trainable, ptlflow_trained\n",
    "\n",
    "try:\n",
    "    import alt_cuda_corr\n",
    "except:\n",
    "    alt_cuda_corr = None\n",
    "\n",
    "if not found_directories:\n",
    "    print(f\"Adding */DPFlow/architecture_files to sys.path\")\n",
    "    #sys.path.append(\"/home/jsorge/private/final_project/DPFlow\")\n",
    "    sys.path.append(\"/home/yix050/private/ECE285_Visual_25Spring/final_project/DPFlow\")\n",
    "    print(f\"sys.path = \")\n",
    "    for idx in range(len(sys.path)):\n",
    "        print(f\"\\t{sys.path[idx]}\") \n",
    "\n",
    "from architecture_files.cross_gated_unit import CrossGateBlock, DownsamplingLayer\n",
    "from architecture_files.res_stem import ResStem\n",
    "from architecture_files.conv_gru_cell import ConvGRUCell\n",
    "from architecture_files.bidirectional_encoder import BidirEncoder\n",
    "\n",
    "# Set device to CUDA\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17ddabe-bda3-4ead-8abe-66b17f93065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial of CGU Block (test for functionality)\n",
    "# # Random Data\n",
    "# batch_dim = 3\n",
    "# channel_in = 3\n",
    "# channel_hidden = 64  # 64, 96, or 128\n",
    "# height = 256\n",
    "# width = 256\n",
    "# rand_data1 = torch.rand((batch_dim, channel_in, height, width), device=device)\n",
    "# rand_data2 = torch.rand((batch_dim, channel_in, height, width), device=device)\n",
    "\n",
    "# # Instantiate Cross-Gated-Unit for testing\n",
    "# model = CrossGateBlock(num_channels_in=channel_in, \n",
    "#                        num_channels_hidden=channel_hidden, \n",
    "#                        norm_type=\"batch_norm\", \n",
    "#                        use_dropout=True, \n",
    "#                        use_layer_scale=False)\n",
    "# model.to(device)\n",
    "# output1, output2 = model(rand_data1, rand_data2)\n",
    "# print(f\"Shape1: {output1.shape}\")\n",
    "# print(f\"Shape2: {output2.shape}\")\n",
    "\n",
    "# channels = 64\n",
    "# groups=8\n",
    "# dummy_data = torch.rand((3, channels, 56, 56), device=device\n",
    "# example = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size(3, 3), stride=2, padding=1, groups=groups, device=device)\n",
    "# example_data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02546a7b-df01-4c8e-8842-efb27fe30e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpflow\n",
      "ptlflow.models.dpflow.dpflow\n",
      "ptlflow.models.dpflow.dpflow\n",
      "ptlflow.models.dpflow.dpflow\n"
     ]
    }
   ],
   "source": [
    "from ptlflow.models.dpflow.dpflow import DPFlow\n",
    "from ptlflow.models.dpflow.dpflow import dpflow\n",
    "\n",
    "print(dpflow.__name__)\n",
    "print(dpflow.__module__)\n",
    "print(DPFlow.__module__)\n",
    "\n",
    "trainable(dpflow)\n",
    "ptlflow_trained(dpflow)\n",
    "c = register_model(dpflow)\n",
    "\n",
    "print(c.__module__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e15b829f-4638-45b8-a708-1d82324f72a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpflow\n",
      "__main__\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Copyright 2025 Henrique Morimitsu\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "class SequenceLoss(nn.Module):\n",
    "    def __init__(self, loss: str, max_flow: float, gamma: float):\n",
    "        super().__init__()\n",
    "        self.loss = loss\n",
    "        self.max_flow = max_flow\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, outputs, inputs):\n",
    "        \"\"\"Loss function defined over sequence of flow predictions\"\"\"\n",
    "\n",
    "        flow_preds = outputs[\"flow_preds\"]\n",
    "        flow_gt = inputs[\"flows\"][:, 0]\n",
    "        valid = inputs[\"valids\"][:, 0]\n",
    "\n",
    "        n_predictions = len(flow_preds)\n",
    "        flow_loss = 0.0\n",
    "\n",
    "        # exclude invalid pixels and extremely large diplacements\n",
    "        mag = torch.sum(flow_gt**2, dim=1, keepdim=True).sqrt()\n",
    "        valid = (valid >= 0.5) & (mag < self.max_flow)\n",
    "\n",
    "        for i in range(n_predictions):\n",
    "            pred = flow_preds[i]\n",
    "            if (\n",
    "                pred.shape[-2] != flow_gt.shape[-2]\n",
    "                or pred.shape[-1] != flow_gt.shape[-1]\n",
    "            ):\n",
    "                pred = F.interpolate(\n",
    "                    pred, size=flow_gt.shape[-2:], mode=\"bilinear\", align_corners=True\n",
    "                )\n",
    "            i_weight = self.gamma ** (n_predictions - i - 1)\n",
    "\n",
    "            if self.loss == \"l1\" or outputs[\"nf_preds\"][i] is None:\n",
    "                diff = pred - flow_gt\n",
    "                i_loss = (diff).abs()\n",
    "                valid_loss = valid * i_loss\n",
    "                flow_loss += i_weight * valid_loss.mean()\n",
    "            elif self.loss == \"laplace\":\n",
    "                loss_i = outputs[\"nf_preds\"][i]\n",
    "                final_mask = (\n",
    "                    (~torch.isnan(loss_i.detach()))\n",
    "                    & (~torch.isinf(loss_i.detach()))\n",
    "                    & valid\n",
    "                )\n",
    "                flow_loss += i_weight * ((final_mask * loss_i).sum() / final_mask.sum())\n",
    "\n",
    "        return flow_loss\n",
    "\n",
    "\n",
    "class DPFlow1(BaseModel):\n",
    "    pretrained_checkpoints = {\n",
    "        \"chairs\": \"https://github.com/hmorimitsu/ptlflow/releases/download/weights1/dpflow-chairs-f94e717a.ckpt\",\n",
    "        \"kitti\": \"https://github.com/hmorimitsu/ptlflow/releases/download/weights1/dpflow-kitti-4e97eac6.ckpt\",\n",
    "        \"sintel\": \"https://github.com/hmorimitsu/ptlflow/releases/download/weights1/dpflow-sintel-b44b072c.ckpt\",\n",
    "        \"spring\": \"https://github.com/hmorimitsu/ptlflow/releases/download/weights1/dpflow-spring-69bac7fa.ckpt\",\n",
    "        \"things\": \"https://github.com/hmorimitsu/ptlflow/releases/download/weights1/dpflow-things-2012b5d6.ckpt\",\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        pyramid_levels: Optional[int] = None,\n",
    "        iters_per_level: int = 4,\n",
    "        detach_flow: bool = True,\n",
    "        use_norm_affine: bool = False,\n",
    "        group_norm_num_groups: int = 8,\n",
    "        corr_mode: str = \"allpairs\",  # \"allpairs\" or \"local\"\n",
    "        corr_levels: int = 1,\n",
    "        corr_range: int = 4,\n",
    "        activation_function: str = \"orig\",  # \"orig\", \"relu\", \"gelu\", \"silu\", or \"mish\"\n",
    "        enc_network: str = \"cgu_bidir_dual\",  # \"cgu\", \"cgu_bidir\", \"cgu_bidir_dual\", \"cgu_dual\", \"next_bidir_dual\", \"swin\"\n",
    "        enc_norm_type: str = \"group\",  # \"none\", \"group\", \"layer\", or \"batch\"\n",
    "        enc_depth: int = 4,\n",
    "        enc_mlp_ratio: float = 2.0,\n",
    "        enc_mlp_in_kernel_size: int = 1,\n",
    "        enc_mlp_out_kernel_size: int = 1,\n",
    "        enc_hidden_chs: list[int] = (64, 96, 128),\n",
    "        enc_num_out_stages: int = 1,\n",
    "        enc_out_1x1_chs: str = \"384\",\n",
    "        dec_gru_norm_type: str = \"layer\",  # \"none\", \"group\", \"layer\", or \"batch\"\n",
    "        dec_gru_iters: int = 1,\n",
    "        dec_gru_depth: int = 4,\n",
    "        dec_gru_mlp_ratio: float = 2.0,\n",
    "        dec_gru_mlp_in_kernel_size: int = 1,\n",
    "        dec_gru_mlp_out_kernel_size: int = 1,\n",
    "        dec_net_chs: int = 128,\n",
    "        dec_inp_chs: int = 128,\n",
    "        dec_motion_chs: int = 128,\n",
    "        dec_flow_kernel_size: int = 7,\n",
    "        dec_flow_head_chs: int = 256,\n",
    "        dec_motenc_corr_hidden_chs: int = 256,\n",
    "        dec_motenc_corr_out_chs: int = 192,\n",
    "        dec_motenc_flow_hidden_chs: int = 128,\n",
    "        dec_motenc_flow_out_chs: int = 64,\n",
    "        use_upsample_mask: bool = True,\n",
    "        upmask_gradient_scale: float = 1.0,\n",
    "        cgu_mlp_dw_kernel_size: int = 7,\n",
    "        cgu_fusion_gate_activation: str = \"gelu\",  # \"linear\", \"sigmoid\", \"relu\", \"gelu\", \"silu\", or \"mish\"\n",
    "        cgu_mlp_use_dw_conv: bool = True,\n",
    "        cgu_mlp_activation_function: str = \"gelu\",  # \"linear\", \"sigmoid\", \"relu\", \"gelu\", \"silu\", or \"mish\"\n",
    "        cgu_layer_scale_init_value: float = 0.01,\n",
    "        loss: str = \"laplace\",  # \"l1\" or \"laplace\"\n",
    "        gamma: float = 0.8,\n",
    "        max_flow: float = 400.0,\n",
    "        use_var: bool = True,\n",
    "        var_min: float = 0.0,\n",
    "        var_max: float = 10.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if pyramid_levels is not None:\n",
    "            assert pyramid_levels > 2, \"Only --model.pyramid_levels >= 3 is supported.\"\n",
    "            output_stride = int(2 ** (pyramid_levels + 2))\n",
    "            if enc_network == \"swin_bidir_dual\":\n",
    "                output_stride *= 2\n",
    "        else:\n",
    "            logger.info(\n",
    "                f\"DPFlow: --model.pyramid_levels is not set, the number of pyramid levels will be inferred from the input size.\"\n",
    "            )\n",
    "            output_stride = None\n",
    "            self.extra_output_stride = 1 if enc_network == \"swin_bidir_dual\" else 0\n",
    "\n",
    "        super(DPFlow, self).__init__(\n",
    "            loss_fn=SequenceLoss(loss=loss, max_flow=max_flow, gamma=gamma),\n",
    "            output_stride=output_stride,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.pyramid_levels = pyramid_levels\n",
    "        self.iters_per_level = iters_per_level\n",
    "        self.corr_mode = corr_mode\n",
    "        self.corr_range = corr_range\n",
    "        self.corr_levels = corr_levels\n",
    "        self.detach_flow = detach_flow\n",
    "        self.loss = loss\n",
    "        self.use_var = use_var\n",
    "        self.var_min = var_min\n",
    "        self.var_max = var_max\n",
    "\n",
    "        activation_function = get_activation(activation_function)\n",
    "\n",
    "        enc_out_1x1_chs = (\n",
    "            float(enc_out_1x1_chs)\n",
    "            if (isinstance(enc_out_1x1_chs, str) and \".\" in enc_out_1x1_chs)\n",
    "            else int(enc_out_1x1_chs)\n",
    "        )\n",
    "\n",
    "        if isinstance(enc_out_1x1_chs, float):\n",
    "            out_1x1_factor = enc_out_1x1_chs\n",
    "            out_1x1_abs_chs = int(enc_out_1x1_chs * enc_hidden_chs[-1])\n",
    "        else:\n",
    "            out_1x1_factor = None\n",
    "            out_1x1_abs_chs = enc_out_1x1_chs\n",
    "\n",
    "        self.max_feat_chs = max(\n",
    "            enc_hidden_chs[-1],\n",
    "            out_1x1_abs_chs,\n",
    "        )\n",
    "\n",
    "        net_chs = dec_net_chs\n",
    "        inp_chs = dec_inp_chs\n",
    "        if net_chs is None or inp_chs is None:\n",
    "            base_chs = out_1x1_abs_chs\n",
    "            if base_chs < 1:\n",
    "                base_chs = enc_hidden_chs[-1]\n",
    "\n",
    "            base_chs = base_chs // 3 * 2\n",
    "\n",
    "            if net_chs is None and inp_chs is None:\n",
    "                net_chs = inp_chs = base_chs // 2\n",
    "            elif net_chs is None and inp_chs is not None:\n",
    "                net_chs = base_chs - inp_chs\n",
    "            elif net_chs is not None and inp_chs is None:\n",
    "                inp_chs = base_chs - net_chs\n",
    "        net_chs_fixed = net_chs\n",
    "        inp_chs_fixed = inp_chs\n",
    "\n",
    "        enc_norm_layer = get_norm(\n",
    "            enc_norm_type,\n",
    "            affine=use_norm_affine,\n",
    "            num_groups=group_norm_num_groups,\n",
    "        )\n",
    "        # self.fnet = CGUBidirDualEncoder(\n",
    "        #     pyramid_levels=pyramid_levels,\n",
    "        #     hidden_chs=enc_hidden_chs,\n",
    "        #     out_1x1_abs_chs=out_1x1_abs_chs,\n",
    "        #     out_1x1_factor=out_1x1_factor,\n",
    "        #     num_out_stages=enc_num_out_stages,\n",
    "        #     activation_function=activation_function,\n",
    "        #     norm_layer=enc_norm_layer,\n",
    "        #     depth=enc_depth,\n",
    "        #     mlp_ratio=enc_mlp_ratio,\n",
    "        #     mlp_use_dw_conv=cgu_mlp_use_dw_conv,\n",
    "        #     mlp_dw_kernel_size=cgu_mlp_dw_kernel_size,\n",
    "        #     mlp_in_kernel_size=enc_mlp_in_kernel_size,\n",
    "        #     mlp_out_kernel_size=enc_mlp_out_kernel_size,\n",
    "        #     cgu_layer_scale_init_value=cgu_layer_scale_init_value,\n",
    "        # )\n",
    "\n",
    "        self.dim_corr = (corr_range * 2 + 1) ** 2 * corr_levels\n",
    "\n",
    "        dec_gru_norm_layer = get_norm(\n",
    "            dec_gru_norm_type,\n",
    "            affine=use_norm_affine,\n",
    "            num_groups=group_norm_num_groups,\n",
    "        )\n",
    "        self.update_block = UpdateBlock(\n",
    "            dec_motenc_corr_hidden_chs=dec_motenc_corr_hidden_chs,\n",
    "            dec_motenc_corr_out_chs=dec_motenc_corr_out_chs,\n",
    "            dec_motenc_flow_hidden_chs=dec_motenc_flow_hidden_chs,\n",
    "            dec_motenc_flow_out_chs=dec_motenc_flow_out_chs,\n",
    "            corr_levels=corr_levels,\n",
    "            corr_range=corr_range,\n",
    "            dec_flow_kernel_size=dec_flow_kernel_size,\n",
    "            dec_motion_chs=dec_motion_chs,\n",
    "            activation_function=activation_function,\n",
    "            net_chs_fixed=net_chs_fixed,\n",
    "            inp_chs_fixed=inp_chs_fixed,\n",
    "            dec_gru_norm_layer=dec_gru_norm_layer,\n",
    "            dec_gru_depth=dec_gru_depth,\n",
    "            dec_gru_iters=dec_gru_iters,\n",
    "            dec_gru_mlp_ratio=dec_gru_mlp_ratio,\n",
    "            cgu_mlp_use_dw_conv=cgu_mlp_use_dw_conv,\n",
    "            cgu_mlp_dw_kernel_size=cgu_mlp_dw_kernel_size,\n",
    "            dec_gru_mlp_in_kernel_size=dec_gru_mlp_in_kernel_size,\n",
    "            dec_gru_mlp_out_kernel_size=dec_gru_mlp_out_kernel_size,\n",
    "            cgu_layer_scale_init_value=cgu_layer_scale_init_value,\n",
    "            dec_flow_head_chs=dec_flow_head_chs,\n",
    "            loss=loss,\n",
    "            use_upsample_mask=use_upsample_mask,\n",
    "            upmask_gradient_scale=upmask_gradient_scale,\n",
    "        )\n",
    "\n",
    "        act = nn.ReLU if activation_function is None else activation_function\n",
    "        self.input_act = act(inplace=True)\n",
    "\n",
    "        self.current_output_stride = output_stride\n",
    "\n",
    "        self.has_shown_input_message = False\n",
    "        self.has_shown_altcuda_message = False\n",
    "\n",
    "    def coords_grid(self, batch, ht, wd):\n",
    "        coords = torch.meshgrid(\n",
    "            torch.arange(ht, dtype=self.dtype, device=self.device),\n",
    "            torch.arange(wd, dtype=self.dtype, device=self.device),\n",
    "            indexing=\"ij\",\n",
    "        )\n",
    "        coords = torch.stack(coords[::-1], dim=0).to(dtype=self.dtype)\n",
    "        return coords[None].repeat(batch, 1, 1, 1)\n",
    "\n",
    "    def upsample_flow(self, flow, mask, factor, ch=2):\n",
    "        \"\"\"Upsample flow field [H/f, W/f, 2] -> [H, W, 2] using convex combination\"\"\"\n",
    "        N, _, H, W = flow.shape\n",
    "        mask = mask.view(N, 1, 9, factor, factor, H, W)\n",
    "        mask = torch.softmax(mask, dim=2)\n",
    "\n",
    "        up_flow = F.unfold(flow, [3, 3], padding=1)\n",
    "        up_flow = up_flow.view(N, ch, 9, 1, 1, H, W)\n",
    "\n",
    "        up_flow = torch.sum(mask * up_flow, dim=2)\n",
    "        up_flow = up_flow.permute(0, 1, 4, 2, 5, 3)\n",
    "        return up_flow.reshape(N, ch, factor * H, factor * W)\n",
    "\n",
    "    def _show_input_message(self, images):\n",
    "        pyr_levels = compute_pyramid_levels(images)\n",
    "        recommended_pyr_levels = pyr_levels  # 3 for 1K, 4 for 2K, etc.\n",
    "\n",
    "        logger.info(\n",
    "            f\"DPFlow: Using {self.pyramid_levels} pyramid levels and {self.iters_per_level} iterations per level.\"\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"DPFlow: Processing inputs of resolution {images.shape[-1]} x {images.shape[-2]}\"\n",
    "        )\n",
    "        logger.info(f\"DPFlow: Correlation mode: {self.corr_mode}\")\n",
    "\n",
    "        if recommended_pyr_levels != self.pyramid_levels:\n",
    "            logger.info(\n",
    "                \"DPFlow: For this input size, you may get better results by setting --pyramid_levels {}\",\n",
    "                recommended_pyr_levels,\n",
    "            )\n",
    "\n",
    "    def _show_altcuda_message(self):\n",
    "        if self.corr_mode == \"local\" and alt_cuda_corr is None:\n",
    "            logger.warning(\n",
    "                f\"DPFlow: You are running with --corr_mode local, but alt_cuda_corr is not installed. Please install alt_cuda_corr to increase the speed.\"\n",
    "            )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        try:\n",
    "            return self.forward_flow(inputs)\n",
    "        except torch.OutOfMemoryError:\n",
    "            if self.corr_mode == \"allpairs\":\n",
    "                logger.warning(\n",
    "                    \"DPFlow: CUDA out of memory error with input size {}. DPFlow will set --model.corr_mode to 'local' and re-attempt inference. This decreases memory consumption, but it is also slower.\",\n",
    "                    list(inputs[\"images\"].shape[-2:]),\n",
    "                )\n",
    "                self.corr_mode = \"local\"\n",
    "                try:\n",
    "                    return self.forward_flow(inputs)\n",
    "                except torch.OutOfMemoryError:\n",
    "                    logger.error(\n",
    "                        \"DPFlow: CUDA out of memory error even after setting --model.corr_mode to 'local'. DPFlow cannot process this input size: {} on this device.\",\n",
    "                        list(inputs[\"images\"].shape[-2:]),\n",
    "                    )\n",
    "            else:\n",
    "                logger.error(\n",
    "                    \"DPFlow: CUDA out of memory error even with --model.corr_mode set to 'local'. DPFlow cannot process this input size: {} on this device.\",\n",
    "                    list(inputs[\"images\"].shape[-2:]),\n",
    "                )\n",
    "\n",
    "    def forward_flow(self, inputs):\n",
    "        if self.corr_mode == \"local\" and not self.has_shown_altcuda_message:\n",
    "            self._show_altcuda_message()\n",
    "            self.has_shown_altcuda_message = True\n",
    "\n",
    "        if self.pyramid_levels is not None and not self.has_shown_input_message:\n",
    "            self._show_input_message(inputs[\"images\"])\n",
    "            self.has_shown_input_message = True\n",
    "\n",
    "        if self.pyramid_levels is None:\n",
    "            pyr_levels = compute_pyramid_levels(inputs[\"images\"])\n",
    "            output_stride = 2 ** (pyr_levels + 2 + self.extra_output_stride)\n",
    "\n",
    "            if output_stride != self.current_output_stride:\n",
    "                logger.info(\n",
    "                    \"DPFlow: Detected change in input size. The number of pyramid levels will change to {}, corresponding to output stride {}.\",\n",
    "                    pyr_levels,\n",
    "                    output_stride,\n",
    "                )\n",
    "                self.current_output_stride = output_stride\n",
    "        else:\n",
    "            pyr_levels = self.pyramid_levels\n",
    "            output_stride = self.output_stride\n",
    "\n",
    "        images, image_resizer = self.preprocess_images(\n",
    "            inputs[\"images\"],\n",
    "            stride=output_stride,\n",
    "            bgr_add=-0.5,\n",
    "            bgr_mult=2.0,\n",
    "            bgr_to_rgb=True,\n",
    "            resize_mode=\"pad\",\n",
    "            pad_mode=\"replicate\",\n",
    "            pad_two_side=True,\n",
    "        )\n",
    "        image1 = images[:, 0]\n",
    "        image2 = images[:, 1]\n",
    "\n",
    "        flow_init = None\n",
    "        if (\n",
    "            inputs.get(\"prev_preds\") is not None\n",
    "            and inputs[\"prev_preds\"].get(\"flow_small\") is not None\n",
    "        ):\n",
    "            flow_init = inputs[\"prev_preds\"][\"flow_small\"]\n",
    "\n",
    "        flow_predictions, flow_small, flow_up, info_predictions = self.predict(\n",
    "            image1,\n",
    "            image2,\n",
    "            pyr_levels=pyr_levels,\n",
    "            image_resizer=image_resizer,\n",
    "            flow_init=flow_init,\n",
    "        )\n",
    "\n",
    "        nf_predictions = []\n",
    "        if self.training and self.loss == \"laplace\":\n",
    "            # exlude invalid pixels and extremely large diplacements\n",
    "            for i in range(len(info_predictions)):\n",
    "                if not self.use_var:\n",
    "                    var_max = var_min = 0\n",
    "                else:\n",
    "                    var_max = self.var_max\n",
    "                    var_min = self.var_min\n",
    "\n",
    "                if info_predictions[i] is None:\n",
    "                    nf_predictions.append(None)\n",
    "                else:\n",
    "                    raw_b = info_predictions[i][:, 2:]\n",
    "                    log_b = torch.zeros_like(raw_b)\n",
    "                    weight = info_predictions[i][:, :2]\n",
    "                    # Large b Component\n",
    "                    log_b[:, 0] = torch.clamp(raw_b[:, 0], min=0, max=var_max)\n",
    "                    # Small b Component\n",
    "                    log_b[:, 1] = torch.clamp(raw_b[:, 1], min=var_min, max=0)\n",
    "                    # term2: [N, 2, m, H, W]\n",
    "                    term2 = (\n",
    "                        (inputs[\"flows\"][:, 0] - flow_predictions[i]).abs().unsqueeze(2)\n",
    "                    ) * (torch.exp(-log_b).unsqueeze(1))\n",
    "                    # term1: [N, m, H, W]\n",
    "                    term1 = weight - math.log(2) - log_b\n",
    "                    nf_loss = torch.logsumexp(\n",
    "                        weight, dim=1, keepdim=True\n",
    "                    ) - torch.logsumexp(term1.unsqueeze(1) - term2, dim=2)\n",
    "                    nf_predictions.append(nf_loss)\n",
    "\n",
    "        outputs = {\"flows\": flow_up[:, None], \"flow_small\": flow_small}\n",
    "\n",
    "        if self.training:\n",
    "            outputs[\"flow_preds\"] = flow_predictions\n",
    "            outputs[\"nf_preds\"] = nf_predictions\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def predict(self, x1_raw, x2_raw, pyr_levels, image_resizer, flow_init=None):\n",
    "        b, _, height_im, width_im = x1_raw.size()\n",
    "\n",
    "        x1_pyramid, x2_pyramid = self.fnet(x1_raw, x2_raw, pyr_levels=pyr_levels)\n",
    "\n",
    "        # outputs\n",
    "        flows = []\n",
    "        infos = []\n",
    "\n",
    "        # init\n",
    "        (\n",
    "            b_size,\n",
    "            _,\n",
    "            h_x1,\n",
    "            w_x1,\n",
    "        ) = x1_pyramid[0].size()\n",
    "        init_device = x1_pyramid[0].device\n",
    "\n",
    "        if flow_init is not None:\n",
    "            flow = flow_init\n",
    "            flow = rescale_flow(\n",
    "                flow,\n",
    "                x1_pyramid[0].shape[-1],\n",
    "                x1_pyramid[0].shape[-2],\n",
    "                to_local=False,\n",
    "            )\n",
    "            flow = upsample2d_as(flow, x1_pyramid[0], mode=\"bilinear\")\n",
    "            flow = forward_interpolate_batch(flow)\n",
    "        else:\n",
    "            flow = torch.zeros(\n",
    "                b_size, 2, h_x1, w_x1, dtype=self.dtype, device=init_device\n",
    "            )\n",
    "\n",
    "        net = None\n",
    "        for l, (x1, x2) in enumerate(zip(x1_pyramid, x2_pyramid)):\n",
    "            # Split feature channels into matching (x) and context (c)\n",
    "            xh = x1.shape[1]\n",
    "            ch = xh // 3\n",
    "            x1, cn1 = torch.split(x1, [xh - ch, ch], dim=1)\n",
    "            x2, cn2 = torch.split(x2, [xh - ch, ch], dim=1)\n",
    "            halfch = ch // 2\n",
    "            i1, n1 = torch.split(cn1, [ch - halfch, halfch], dim=1)\n",
    "            i2, n2 = torch.split(cn2, [ch - halfch, halfch], dim=1)\n",
    "            inp = torch.cat([i1, i2], 1)\n",
    "            inp = self.input_act(inp)\n",
    "            net_tmp = torch.cat([n1, n2], 1)\n",
    "\n",
    "            coords0 = self.coords_grid(x1.shape[0], x1.shape[2], x1.shape[3])\n",
    "\n",
    "            if self.corr_mode == \"allpairs\":\n",
    "                corr_fn = CorrBlock(x1, x2, self.corr_levels, self.corr_range)\n",
    "            else:\n",
    "                corr_fn = AlternateCorrBlock(x1, x2, self.corr_levels, self.corr_range)\n",
    "\n",
    "            if l > 0:\n",
    "                flow = rescale_flow(flow, x1.shape[-1], x1.shape[-2], to_local=False)\n",
    "                flow = upsample2d_as(flow, x1, mode=\"bilinear\")\n",
    "\n",
    "            net = torch.tanh(net_tmp)\n",
    "\n",
    "            for it in range(self.iters_per_level):\n",
    "                if self.detach_flow:\n",
    "                    flow = flow.detach()\n",
    "\n",
    "                # correlation\n",
    "                out_corr = corr_fn(coords0 + flow)\n",
    "\n",
    "                flow_res, net, mask = self.update_block(net, inp, out_corr, flow)\n",
    "\n",
    "                info = None\n",
    "                if self.loss == \"laplace\":\n",
    "                    info = flow_res[:, 2:]\n",
    "                    flow_res = flow_res[:, :2]\n",
    "\n",
    "                flow = flow + flow_res\n",
    "\n",
    "                if self.training or (\n",
    "                    l == len(x1_pyramid) - 1 and it == self.iters_per_level - 1\n",
    "                ):\n",
    "                    out_flow = rescale_flow(flow, width_im, height_im, to_local=False)\n",
    "                    if mask is not None:\n",
    "                        out_flow = self.upsample_flow(out_flow, mask, factor=8)\n",
    "                    out_flow = upsample2d_as(out_flow, x1_raw, mode=\"bilinear\")\n",
    "                    out_flow = self.postprocess_predictions(\n",
    "                        out_flow, image_resizer, is_flow=True\n",
    "                    )\n",
    "                    flows.append(out_flow)\n",
    "\n",
    "                    out_info = None\n",
    "                    if info is not None:\n",
    "                        if mask is not None:\n",
    "                            out_info = self.upsample_flow(info, mask, factor=8, ch=4)\n",
    "                        out_info = upsample2d_as(out_info, x1_raw, mode=\"bilinear\")\n",
    "                        out_info = self.postprocess_predictions(\n",
    "                            out_info, image_resizer, is_flow=False\n",
    "                        )\n",
    "                    infos.append(out_info)\n",
    "\n",
    "        return flows, flow, out_flow, infos\n",
    "\n",
    "\n",
    "#@register_model\n",
    "@trainable\n",
    "@ptlflow_trained\n",
    "class dpflow(DPFlow):\n",
    "    \n",
    "    pass\n",
    "\n",
    "print(dpflow.__name__)\n",
    "print(dpflow.__module__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffbefce-8e88-4845-83bb-1864610a2ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11kernel",
   "language": "python",
   "name": "py11kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
